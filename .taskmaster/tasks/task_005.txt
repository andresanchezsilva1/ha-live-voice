# Task ID: 5
# Title: Implement Frontend Audio Capture
# Status: done
# Dependencies: 1
# Priority: medium
# Description: Develop the frontend functionality to capture audio from the user's microphone and stream it to the backend via WebSocket.
# Details:
1. Create an audio capture composable in frontend/src/composables/useAudioCapture.ts:
```typescript
import { ref, onUnmounted } from 'vue'

export function useAudioCapture() {
  const isRecording = ref(false)
  const audioContext = ref<AudioContext | null>(null)
  const mediaStream = ref<MediaStream | null>(null)
  const processor = ref<ScriptProcessorNode | null>(null)
  const websocket = ref<WebSocket | null>(null)
  
  const startRecording = async (wsUrl: string) => {
    try {
      // Initialize WebSocket
      websocket.value = new WebSocket(wsUrl)
      
      await new Promise((resolve, reject) => {
        websocket.value!.onopen = resolve
        websocket.value!.onerror = reject
      })
      
      // Initialize audio context and stream
      audioContext.value = new AudioContext()
      mediaStream.value = await navigator.mediaDevices.getUserMedia({
        audio: {
          channelCount: 1,
          sampleRate: 16000
        }
      })
      
      // Create processor to handle audio data
      processor.value = audioContext.value.createScriptProcessor(4096, 1, 1)
      
      // Connect audio nodes
      const source = audioContext.value.createMediaStreamSource(mediaStream.value)
      source.connect(processor.value)
      processor.value.connect(audioContext.value.destination)
      
      // Process audio data
      processor.value.onaudioprocess = (e) => {
        if (!isRecording.value) return
        
        const inputData = e.inputBuffer.getChannelData(0)
        const pcmData = convertFloat32ToInt16(inputData)
        
        if (websocket.value?.readyState === WebSocket.OPEN) {
          websocket.value.send(pcmData)
        }
      }
      
      isRecording.value = true
    } catch (error) {
      console.error('Error starting recording:', error)
      throw error
    }
  }
  
  const stopRecording = () => {
    isRecording.value = false
    
    if (processor.value) {
      processor.value.disconnect()
      processor.value = null
    }
    
    if (mediaStream.value) {
      mediaStream.value.getTracks().forEach(track => track.stop())
      mediaStream.value = null
    }
    
    if (audioContext.value) {
      audioContext.value.close()
      audioContext.value = null
    }
    
    if (websocket.value) {
      websocket.value.close()
      websocket.value = null
    }
  }
  
  // Convert Float32Array to Int16Array for PCM format
  const convertFloat32ToInt16 = (buffer: Float32Array) => {
    const l = buffer.length
    const buf = new Int16Array(l)
    
    for (let i = 0; i < l; i++) {
      buf[i] = Math.min(1, Math.max(-1, buffer[i])) * 0x7FFF
    }
    
    return buf.buffer
  }
  
  onUnmounted(() => {
    stopRecording()
  })
  
  return {
    isRecording,
    startRecording,
    stopRecording
  }
}
```

2. Create an audio visualization component using vue-audio-visual:
```vue
<template>
  <div class="audio-visualizer">
    <canvas ref="canvas" :width="width" :height="height"></canvas>
  </div>
</template>

<script setup lang="ts">
import { ref, onMounted, onUnmounted, watch } from 'vue'

const props = defineProps<{
  mediaStream: MediaStream | null
  width: number
  height: number
}>()

const canvas = ref<HTMLCanvasElement | null>(null)
let animationFrame: number | null = null
let audioContext: AudioContext | null = null
let analyser: AnalyserNode | null = null
let dataArray: Uint8Array | null = null

const setupAnalyser = () => {
  if (!props.mediaStream) return
  
  audioContext = new AudioContext()
  analyser = audioContext.createAnalyser()
  analyser.fftSize = 256
  
  const source = audioContext.createMediaStreamSource(props.mediaStream)
  source.connect(analyser)
  
  const bufferLength = analyser.frequencyBinCount
  dataArray = new Uint8Array(bufferLength)
  
  draw()
}

const draw = () => {
  if (!canvas.value || !analyser || !dataArray) return
  
  animationFrame = requestAnimationFrame(draw)
  
  const canvasCtx = canvas.value.getContext('2d')
  if (!canvasCtx) return
  
  analyser.getByteFrequencyData(dataArray)
  
  canvasCtx.fillStyle = 'rgb(0, 0, 0)'
  canvasCtx.fillRect(0, 0, props.width, props.height)
  
  const barWidth = (props.width / dataArray.length) * 2.5
  let barHeight: number
  let x = 0
  
  for (let i = 0; i < dataArray.length; i++) {
    barHeight = dataArray[i] / 2
    
    canvasCtx.fillStyle = `rgb(${barHeight + 100}, 50, 50)`
    canvasCtx.fillRect(x, props.height - barHeight, barWidth, barHeight)
    
    x += barWidth + 1
  }
}

watch(() => props.mediaStream, (newStream) => {
  if (newStream) {
    setupAnalyser()
  }
})

onMounted(() => {
  if (props.mediaStream) {
    setupAnalyser()
  }
})

onUnmounted(() => {
  if (animationFrame) {
    cancelAnimationFrame(animationFrame)
  }
  
  if (audioContext) {
    audioContext.close()
  }
})
</script>
```

3. Implement error handling and reconnection logic for WebSocket
4. Add visual indicators for recording state
5. Ensure proper cleanup of audio resources when component is unmounted

# Test Strategy:
1. Test microphone access permissions
2. Verify audio capture starts and stops correctly
3. Test WebSocket connection establishment and data transmission
4. Validate audio format conversion (Float32 to Int16)
5. Test visualization component with sample audio data
6. Verify resource cleanup on component unmount
7. Test across different browsers for compatibility

# Subtasks:
## 1. Implement MediaDevices API configuration [done]
### Dependencies: None
### Description: Set up the MediaDevices API to access the user's microphone and handle permissions
### Details:
Use navigator.mediaDevices.getUserMedia() to request microphone access. Handle user permissions and potential errors. Ensure proper audio constraints are set (e.g., channelCount: 1, sampleRate: 16000).
<info added on 2025-06-08T04:03:28.100Z>
Implementa√ß√£o completa da configura√ß√£o do MediaDevices API:

‚úÖ **Funcionalidades implementadas:**
- Verifica√ß√£o de suporte do navegador para MediaDevices e Web Audio API
- Solicita√ß√£o de permiss√£o para acesso ao microfone com tratamento de diferentes tipos de erro
- Configura√ß√£o de constraints de √°udio (channelCount, sampleRate, echoCancellation, noiseSuppression)
- Tratamento detalhado de erros com c√≥digos espec√≠ficos:
  - NotAllowedError: Permiss√£o negada
  - NotFoundError: Microfone n√£o encontrado
  - NotReadableError: Microfone em uso
  - OverconstrainedError: Configura√ß√µes n√£o suportadas
- Listagem de dispositivos de √°udio dispon√≠veis
- Limpeza autom√°tica de recursos no unmount do componente

‚úÖ **Configura√ß√µes padr√£o implementadas:**
- channelCount: 1 (mono)
- sampleRate: 16000 Hz (ideal para speech processing)
- echoCancellation: true
- noiseSuppression: true

‚úÖ **Tratamento de erros robusto:**
- Interface AudioCaptureError com code, message e details
- Fun√ß√£o setError para padroniza√ß√£o de erros
- clearError para reset de estado de erro

O composable est√° pronto para ser usado por componentes Vue e fornece uma interface reativa completa para gerenciar permiss√µes e configura√ß√µes de √°udio.
</info added on 2025-06-08T04:03:28.100Z>

## 2. Implement real-time audio capture [done]
### Dependencies: 5.1
### Description: Capture audio data in real-time using Web Audio API
### Details:
Create an AudioContext and ScriptProcessorNode to process audio data. Implement the onaudioprocess event handler to capture audio frames. Ensure efficient processing to avoid audio glitches.
<info added on 2025-06-08T04:05:07.343Z>
The audio capture implementation has been completed with the following components:

1. AudioContext and ScriptProcessorNode (4096 buffer size) configuration
2. Real-time audio processing through the onaudioprocess event handler
3. Automatic conversion from Float32Array to Int16Array (PCM format)
4. WebSocket integration for continuous data transmission
5. Connection state verification before sending data
6. Comprehensive error handling

A test component (AudioCaptureTest.vue) was created with:
- Complete interface for audio capture testing
- Dynamic parameter configuration (sampleRate, echo cancellation)
- Connection and recording state visualization
- Real-time event logging
- MediaStream and tracks detailed information
- Available audio devices listing
- Recording controls
- Error display with specific codes

Technical specifications:
- 4096 samples buffer size for low latency
- Continuous processing during recording
- State verification before processing/sending
- Automatic resource cleanup
- WebSocket disconnection handling

The system is now ready for real-time audio capture and WebSocket transmission to the backend.
</info added on 2025-06-08T04:05:07.343Z>

## 3. Implement audio format conversion [done]
### Dependencies: 5.2
### Description: Convert captured audio data to the appropriate format for backend processing
### Details:
Convert Float32Array audio data to Int16Array for PCM format. Implement the convertFloat32ToInt16 function as shown in the current implementation. Ensure proper scaling and clamping of values.
<info added on 2025-06-08T04:05:32.810Z>
Convers√£o de formato de √°udio implementada com sucesso:

‚úÖ **Fun√ß√£o convertFloat32ToInt16 implementada:**
```typescript
const convertFloat32ToInt16 = (buffer: Float32Array): ArrayBuffer => {
  const l = buffer.length
  const buf = new Int16Array(l)

  for (let i = 0; i < l; i++) {
    // Clamping e scaling para Int16
    const sample = Math.min(1, Math.max(-1, buffer[i]))
    buf[i] = sample * 0x7FFF
  }

  return buf.buffer
}
```

‚úÖ **Caracter√≠sticas da convers√£o:**
- **Input:** Float32Array (valores entre -1.0 e 1.0)
- **Output:** ArrayBuffer contendo Int16Array (valores entre -32768 e 32767)
- **Clamping:** Garante que valores estejam no range [-1, 1] antes da convers√£o
- **Scaling:** Multiplica por 0x7FFF (32767) para m√°xima precis√£o
- **Formato resultante:** PCM 16-bit, adequado para processamento de speech

‚úÖ **Integra√ß√£o no processo de captura:**
- Convers√£o autom√°tica realizada no handler onaudioprocess
- Buffer convertido √© enviado diretamente via WebSocket
- Compat√≠vel com o formato esperado pelo backend Gemini Live API

‚úÖ **Valida√ß√µes implementadas:**
- Verifica√ß√£o de bounds para evitar overflow
- Tratamento de valores NaN ou infinitos atrav√©s do clamping
- Preserva√ß√£o da qualidade de √°udio durante convers√£o

A convers√£o est√° otimizada para baixa lat√™ncia e adequada para streaming em tempo real.
</info added on 2025-06-08T04:05:32.810Z>

## 4. Implement WebSocket communication [done]
### Dependencies: 5.3
### Description: Set up WebSocket connection and send audio data to the backend
### Details:
Establish WebSocket connection when starting recording. Implement error handling and reconnection logic. Send converted audio data in chunks via WebSocket. Close connection properly when stopping recording.
<info added on 2025-06-08T04:06:00.711Z>
WebSocket communication implemented with advanced features:

‚úÖ **Connection establishment with timeout:**
- 10-second timeout for initial connection
- Promise-based connection establishment
- Handling of onopen, onerror, onclose events

‚úÖ **Automatic reconnection system:**
- Maximum of 3 reconnection attempts
- Exponential backoff (retryDelay * 2^attempt)
- Automatic reconnection in case of disconnection during recording
- Counter reset after successful connection

‚úÖ **Robust data transmission:**
- readyState verification before sending
- Try-catch to capture sending errors
- Detailed transmission error logs
- Continuous sending of ArrayBuffer (PCM data)

‚úÖ **State management:**
- Tracking of connectionRetryCount
- isConnecting states for UI feedback
- Automatic connection cleanup when stopping recording

‚úÖ **WebSocket event handling:**
```typescript
ws.onopen = () => {
  clearTimeout(connectionTimeout)
  connectionRetryCount.value = 0
  console.log('WebSocket connected successfully')
  resolve(ws)
}

ws.onclose = (event) => {
  console.log('WebSocket closed:', event.code, event.reason)
  
  // Auto-reconnect if recording was in progress
  if (isRecording.value && connectionRetryCount.value < maxRetries) {
    setTimeout(() => {
      connectionRetryCount.value++
      reconnectWebSocket(wsUrl)
    }, retryDelay * Math.pow(2, connectionRetryCount.value))
  }
}
```

‚úÖ **Reliability features:**
- Connection timeout handling
- Cleanup logic in case of failure
- Visual states for user (connecting, error, success)
- Complete integration with the audio capture system

The WebSocket communication is robust and production-ready.
</info added on 2025-06-08T04:06:00.711Z>

## 5. Develop user interface for audio capture control [done]
### Dependencies: 5.1, 5.2, 5.3, 5.4
### Description: Create a Vue component for controlling audio capture and displaying status
### Details:
Implement start/stop recording buttons. Display recording status and error messages. Integrate AudioVisualizer component for visual feedback. Ensure proper state management and component lifecycle handling.
<info added on 2025-06-08T04:06:26.260Z>
Interface do usu√°rio para controle de captura de √°udio implementada completa:

‚úÖ **Componente AudioCaptureTest.vue criado com recursos completos:**

**üéõÔ∏è Controles de grava√ß√£o:**
- Bot√£o "Iniciar Grava√ß√£o" com estados din√¢micos
- Bot√£o "Parar Grava√ß√£o" 
- Bot√£o "Testar Suporte do Navegador"
- Desabilita√ß√£o inteligente baseada no estado atual

**üìä Indicadores de status visuais:**
- Status em tempo real (Inativo, Conectando, Gravando, Erro)
- Classes CSS din√¢micas com cores espec√≠ficas
- Loading spinner animado durante conex√£o
- Estados computados reativos

**‚öôÔ∏è Configura√ß√µes de √°udio interativas:**
- Sample Rate configur√°vel (8k, 16k, 44.1k, 48k Hz)
- Toggle Echo Cancellation
- Toggle Noise Suppression
- URL WebSocket edit√°vel

**üé§ Informa√ß√µes de dispositivos:**
- Listagem autom√°tica de dispositivos de √°udio
- Carregamento na inicializa√ß√£o do componente
- Labels descritivos ou fallback para IDs

**üì± Monitoramento do MediaStream:**
- Informa√ß√µes detalhadas dos tracks ativos
- Configura√ß√µes do √°udio em tempo real
- Estado dos tracks (readyState)
- Visualiza√ß√£o JSON das configura√ß√µes

**‚ùå Tratamento de erros avan√ßado:**
- Exibi√ß√£o de c√≥digo, mensagem e detalhes
- Bot√£o para limpar erros
- Styling visual para destacar erros

**üìù Sistema de logs em tempo real:**
- Log timestamped de todos os eventos
- Categoriza√ß√£o por tipo (info, success, error)
- Container scroll√°vel com √∫ltimos 20 eventos
- Cores diferenciadas por tipo de evento

**üé® Design responsivo e moderno:**
- Layout grid adaptativo
- Estilo GitHub-like
- Anima√ß√µes e transi√ß√µes suaves
- Tipografia consistente
</info added on 2025-06-08T04:06:26.260Z>
<info added on 2025-06-08T04:17:21.647Z>
**üîß CORRE√á√ïES APLICADAS PARA DESCONEX√ÉO LIMPA:**

**Frontend (useAudioCapture.ts):**
‚úÖ **Sequ√™ncia de cleanup otimizada:**
- Remove callback `onaudioprocess` imediatamente (para o envio)
- Para tracks de √°udio primeiro
- Fecha AudioContext com promise handling
- WebSocket fecha por √∫ltimo com delay de 100ms e c√≥digo 1000 (normal closure)
- Logs detalhados para debugging

**Backend (websocket_handler.py):**
‚úÖ **Detec√ß√£o inteligente de desconex√£o:**
- Detec√ß√£o de palavras-chave ("disconnect", "closed", "cannot call receive")
- Processamento de √°udio sem recovery para evitar tentativas desnecess√°rias
- Verifica√ß√£o dupla de conex√£o ativa antes de envio de mensagens
- Diferencia√ß√£o entre erros de desconex√£o vs. erros reais

‚úÖ **Melhorias no _send_structured_message:**
- Verifica√ß√£o pr√©via se conex√£o est√° ativa
- Skip de envio se conex√£o j√° foi fechada
- Recovery apenas para erros n√£o relacionados √† desconex√£o
- Logs debug (n√£o error) para erros de desconex√£o

**üéØ Resultado esperado:**
- Captura funciona perfeitamente
- Desconex√£o limpa sem erros nos logs
- Reconex√£o imediata funcionando
- Elimina√ß√£o dos race conditions
</info added on 2025-06-08T04:17:21.647Z>

