#!/usr/bin/env python3
"""
Cliente Gemini Live API - Implementa√ß√£o oficial baseada na documenta√ß√£o
https://ai.google.dev/gemini-api/docs/live?hl=pt-br

Este cliente implementa o streaming de √°udio bidirecional em tempo real
usando a Live API oficial do Gemini conforme a documenta√ß√£o.
"""

import asyncio
import logging
import json
import time
from typing import Any, Dict, List, Optional, Callable, Union
from google import genai
from google.genai import types
import numpy as np

logger = logging.getLogger(__name__)


class GeminiLiveAPIClient:
    """
    Cliente oficial da Live API do Gemini para streaming de √°udio bidirecional
    
    Baseado na documenta√ß√£o oficial:
    https://ai.google.dev/gemini-api/docs/live?hl=pt-br
    """
    
    def __init__(self, api_key: str, model: str = "gemini-2.5-flash-preview-native-audio-dialog"):
        """
        Inicializa o cliente da Live API
        
        Args:
            api_key: Chave da API do Google AI
            model: Modelo a ser usado (padr√£o: gemini-2.5-flash-preview-native-audio-dialog)
        """
        self.api_key = api_key
        self.model = model
        self.client = genai.Client(api_key=api_key)
        self.session = None
        self.is_connected = False
        self.function_declarations = []
        
        logger.info(f"Cliente Live API inicializado - modelo: {model}")
    
    def set_function_declarations(self, function_declarations: List[Dict[str, Any]]):
        """
        Define as declara√ß√µes de fun√ß√£o para function calling
        
        Args:
            function_declarations: Lista de declara√ß√µes de fun√ß√£o
        """
        self.function_declarations = function_declarations
        logger.info(f"Configuradas {len(function_declarations)} declara√ß√µes de fun√ß√£o")
    
    async def connect_audio_session(
        self,
        system_instruction: Optional[str] = None,
        voice_name: str = "Kore",
        language_code: str = "pt-BR",
        enable_function_calling: bool = True
    ) -> Any:
        """
        Conecta √† Live API com configura√ß√£o para √°udio
        
        Args:
            system_instruction: Instru√ß√µes do sistema
            voice_name: Nome da voz (Puck, Charon, Kore, Fenrir, Aoede, Leda, Orus, Zephyr)
            language_code: C√≥digo do idioma (pt-BR para portugu√™s brasileiro)
            enable_function_calling: Se deve habilitar function calling
            
        Returns:
            Context manager da sess√£o ativa da Live API
        """
        try:
            # Configura√ß√£o da sess√£o
            config = {
                "response_modalities": ["AUDIO"],  # Volta para s√≥ √°udio como estava funcionando
                "speech_config": {
                    "voice_config": {
                        "prebuilt_voice_config": {
                            "voice_name": voice_name
                        }
                    },
                    "language_code": language_code
                }
            }
            
            # Adicionar system instruction se fornecido
            if system_instruction:
                config["system_instruction"] = system_instruction
            
            # Adicionar tools se function calling estiver habilitado
            if enable_function_calling and self.function_declarations:
                config["tools"] = [{"function_declarations": self.function_declarations}]
            
            # Conectar √† Live API - retorna o context manager diretamente
            session_context = self.client.aio.live.connect(
                model=self.model,
                config=config
            )
            
            self.is_connected = True
            logger.info("Conectado √† Live API com sucesso")
            logger.info(f"Configura√ß√£o: voz={voice_name}, idioma={language_code}")
            
            return session_context
            
        except Exception as e:
            logger.error(f"Erro ao conectar √† Live API: {e}")
            raise
    
    async def connect_text_session(
        self,
        system_instruction: Optional[str] = None,
        enable_function_calling: bool = True
    ) -> Any:
        """
        Conecta √† Live API com configura√ß√£o para texto
        
        Args:
            system_instruction: Instru√ß√µes do sistema
            enable_function_calling: Se deve habilitar function calling
            
        Returns:
            Context manager da sess√£o ativa da Live API
        """
        try:
            # Configura√ß√£o da sess√£o
            config = {
                "response_modalities": ["TEXT"]  # Resposta em texto
            }
            
            # Adicionar system instruction se fornecido
            if system_instruction:
                config["system_instruction"] = system_instruction
            
            # Adicionar tools se function calling estiver habilitado
            if enable_function_calling and self.function_declarations:
                config["tools"] = [{"function_declarations": self.function_declarations}]
            
            # Conectar √† Live API - retorna o context manager diretamente
            session_context = self.client.aio.live.connect(
                model=self.model,
                config=config
            )
            
            self.is_connected = True
            logger.info("Conectado √† Live API (modo texto) com sucesso")
            
            return session_context
            
        except Exception as e:
            logger.error(f"Erro ao conectar √† Live API: {e}")
            raise
    
    async def send_text_message(self, message: str, turn_complete: bool = True):
        """
        Envia uma mensagem de texto
        
        Args:
            message: Texto da mensagem
            turn_complete: Se deve marcar o turno como completo
        """
        if not self.is_connected or not self.session:
            raise RuntimeError("N√£o conectado √† Live API")
        
        try:
            await self.session.send_client_content(
                turns={"role": "user", "parts": [{"text": message}]},
                turn_complete=turn_complete
            )
            logger.info(f"Mensagem texto enviada: {message[:50]}...")
            
        except Exception as e:
            logger.error(f"Erro ao enviar mensagem de texto: {e}")
            raise
    
    async def send_audio_data(
        self,
        audio_data: bytes,
        mime_type: str = "audio/pcm;rate=16000"
    ):
        """
        Envia dados de √°udio em tempo real
        
        Args:
            audio_data: Dados de √°udio em bytes (16-bit PCM, 16kHz, mono)
            mime_type: Tipo MIME do √°udio
        """
        if not self.is_connected or not self.session:
            raise RuntimeError("N√£o conectado √† Live API")
        
        try:
            await self.session.send_realtime_input(
                audio=types.Blob(data=audio_data, mime_type=mime_type)
            )
            logger.debug(f"Dados de √°udio enviados: {len(audio_data)} bytes")
            
        except Exception as e:
            logger.error(f"Erro ao enviar dados de √°udio: {e}")
            raise

    async def send_turn_complete(self):
        """
        Sinaliza ao Gemini que o turno do usu√°rio terminou e ele deve responder
        Baseado na documenta√ß√£o oficial: https://ai.google.dev/api/live
        """
        if not self.is_connected or not self.session:
            raise RuntimeError("N√£o conectado √† Live API")
        
        try:
            # Baseado na documenta√ß√£o oficial do Google Gemini Live API
            # Para sinalizar fim do turno ap√≥s enviar √°udio, usamos send_client_content
            # com turns vazio e turn_complete=True
            await self.session.send_client_content(
                turns=[],  # Lista vazia de turnos
                turn_complete=True  # Sinaliza fim do turno
            )
            logger.debug("Turn complete sinalizado ao Gemini usando send_client_content")
            
        except Exception as e:
            logger.error(f"Erro ao enviar turn complete: {e}")
            raise
    
    async def receive_responses(
        self,
        text_callback: Optional[Callable[[str], None]] = None,
        audio_callback: Optional[Callable[[bytes], None]] = None,
        function_call_callback: Optional[Callable[[List[Any]], None]] = None
    ):
        """
        Recebe respostas da Live API
        
        Args:
            text_callback: Callback para texto recebido
            audio_callback: Callback para √°udio recebido
            function_call_callback: Callback para chamadas de fun√ß√£o
        """
        if not self.is_connected or not self.session:
            raise RuntimeError("N√£o conectado √† Live API")
        
        try:
            async for response in self.session.receive():
                logger.info(f"üîç [GEMINI-RESPONSE] Received response type: {type(response)}, hasattr text: {hasattr(response, 'text')}, hasattr data: {hasattr(response, 'data')}, hasattr server_content: {hasattr(response, 'server_content')}")
                
                # Log all available attributes for debugging
                response_attrs = [attr for attr in dir(response) if not attr.startswith('_')]
                logger.debug(f"üîç [GEMINI-RESPONSE] Available attributes: {response_attrs}")
                
                # Processar texto direto
                if hasattr(response, 'text') and response.text is not None and text_callback:
                    logger.info(f"üìù [GEMINI-TEXT] Processing direct text response: {response.text[:100]}...")
                    text_callback(response.text)
                
                # Processar √°udio direto
                if hasattr(response, 'data') and response.data is not None and audio_callback:
                    logger.info(f"üéµ [GEMINI-AUDIO] Processing direct audio response: {len(response.data)} bytes")
                    audio_callback(response.data)
                
                # Processar chamadas de fun√ß√£o
                if hasattr(response, 'tool_call') and response.tool_call and function_call_callback:
                    logger.info(f"üîß [GEMINI-FUNCTION] Processing function call response")
                    function_call_callback(response.tool_call.function_calls)
                
                # Processar conte√∫do do servidor
                if hasattr(response, 'server_content') and response.server_content:
                    server_content = response.server_content
                    logger.info(f"üîç [GEMINI-SERVER] Processing server_content, hasattr interrupted: {hasattr(server_content, 'interrupted')}, hasattr generation_complete: {hasattr(server_content, 'generation_complete')}, hasattr model_turn: {hasattr(server_content, 'model_turn')}")
                    
                    # Verificar se foi interrompido
                    if hasattr(server_content, 'interrupted') and server_content.interrupted:
                        logger.info("‚ö†Ô∏è [GEMINI-INTERRUPT] Gera√ß√£o interrompida pelo usu√°rio")
                        break
                    
                    # Verificar se a gera√ß√£o est√° completa
                    if hasattr(server_content, 'generation_complete') and server_content.generation_complete:
                        logger.info("‚úÖ [GEMINI-COMPLETE] Gera√ß√£o completa")
                        break
                    
                    # Processar conte√∫do do modelo
                    if hasattr(server_content, 'model_turn') and server_content.model_turn:
                        model_turn = server_content.model_turn
                        logger.info(f"üîç [GEMINI-TURN] Processing model_turn, hasattr parts: {hasattr(model_turn, 'parts')}")
                        
                        if hasattr(model_turn, 'parts') and model_turn.parts:
                            logger.info(f"üîç [GEMINI-PARTS] Found {len(model_turn.parts)} parts")
                            for i, part in enumerate(model_turn.parts):
                                part_attrs = [attr for attr in dir(part) if not attr.startswith('_')]
                                logger.info(f"üîç [GEMINI-PART-{i}] Part attributes: {part_attrs}")
                                
                                # Texto
                                if hasattr(part, 'text') and part.text and text_callback:
                                    logger.info(f"üìù [GEMINI-PART-TEXT] Processing text from part {i}: {part.text[:100]}...")
                                    text_callback(part.text)
                                
                                # Dados inline (√°udio)
                                if hasattr(part, 'inline_data') and part.inline_data and audio_callback:
                                    logger.info(f"üéµ [GEMINI-PART-AUDIO] Found inline_data in part {i}")
                                    if hasattr(part.inline_data, 'data'):
                                        logger.info(f"üéµ [GEMINI-PART-AUDIO] Processing audio data: {len(part.inline_data.data)} bytes")
                                        audio_callback(part.inline_data.data)
                                    elif hasattr(part.inline_data, 'bytes'):
                                        logger.info(f"üéµ [GEMINI-PART-AUDIO] Processing audio bytes: {len(part.inline_data.bytes)} bytes")
                                        audio_callback(part.inline_data.bytes)
                                    else:
                                        inline_data_attrs = [attr for attr in dir(part.inline_data) if not attr.startswith('_')]
                                        logger.warning(f"üéµ [GEMINI-PART-AUDIO] inline_data found but no data/bytes attributes. Available: {inline_data_attrs}")
                                else:
                                    if hasattr(part, 'inline_data'):
                                        logger.info(f"üîç [GEMINI-PART-{i}] Has inline_data but no audio_callback or data is None")
                                    else:
                                        logger.info(f"üîç [GEMINI-PART-{i}] No inline_data found")
                
        except Exception as e:
            logger.error(f"Erro ao receber respostas: {e}")
            raise
    
    async def send_function_response(
        self,
        function_responses: List[Dict[str, Any]]
    ):
        """
        Envia resposta de uma chamada de fun√ß√£o
        
        Args:
            function_responses: Lista de respostas de fun√ß√£o
        """
        if not self.is_connected or not self.session:
            raise RuntimeError("N√£o conectado √† Live API")
        
        try:
            # Converter para o formato correto
            responses = []
            for resp in function_responses:
                function_response = types.FunctionResponse(
                    id=resp.get("id"),
                    name=resp.get("name"),
                    response=resp.get("response", {})
                )
                responses.append(function_response)
            
            await self.session.send_tool_response(function_responses=responses)
            logger.info(f"Enviadas {len(responses)} respostas de fun√ß√£o")
            
        except Exception as e:
            logger.error(f"Erro ao enviar resposta de fun√ß√£o: {e}")
            raise
    
    async def disconnect(self):
        """
        Desconecta da Live API
        """
        if self.session and self.is_connected:
            try:
                # A sess√£o ser√° fechada automaticamente quando sair do context manager
                self.is_connected = False
                self.session = None
                logger.info("Desconectado da Live API")
                
            except Exception as e:
                logger.error(f"Erro ao desconectar: {e}")
    
    def process_audio_for_live_api(self, audio_data: np.ndarray, sample_rate: int = 16000) -> bytes:
        """
        Processa dados de √°udio para o formato correto da Live API
        
        Args:
            audio_data: Array numpy com dados de √°udio
            sample_rate: Taxa de amostragem (deve ser 16000 para entrada)
            
        Returns:
            Dados de √°udio em bytes (16-bit PCM, little-endian)
        """
        try:
            # Garantir que est√° em 16-bit PCM
            if audio_data.dtype != np.int16:
                # Normalizar e converter para int16
                audio_data = (audio_data * 32767).astype(np.int16)
            
            # Garantir que √© mono
            if len(audio_data.shape) > 1:
                audio_data = np.mean(audio_data, axis=1).astype(np.int16)
            
            # Converter para bytes (little-endian)
            audio_bytes = audio_data.tobytes()
            
            logger.debug(f"√Åudio processado: {len(audio_bytes)} bytes, taxa: {sample_rate}Hz")
            return audio_bytes
            
        except Exception as e:
            logger.error(f"Erro ao processar √°udio: {e}")
            raise
    
    def process_audio_from_live_api(self, audio_bytes: bytes, sample_rate: int = 24000) -> np.ndarray:
        """
        Processa dados de √°udio recebidos da Live API
        
        Args:
            audio_bytes: Dados de √°udio em bytes da Live API
            sample_rate: Taxa de amostragem (24000 para sa√≠da da Live API)
            
        Returns:
            Array numpy com dados de √°udio
        """
        try:
            # Converter bytes para array numpy (16-bit PCM, little-endian)
            audio_data = np.frombuffer(audio_bytes, dtype=np.int16)
            
            logger.debug(f"√Åudio recebido: {len(audio_data)} samples, taxa: {sample_rate}Hz")
            return audio_data
            
        except Exception as e:
            logger.error(f"Erro ao processar √°udio recebido: {e}")
            raise 