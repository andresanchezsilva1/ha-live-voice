import { ref, onUnmounted } from 'vue'

export interface AudioCaptureConfig {
  channelCount?: number
  sampleRate?: number
  echoCancellation?: boolean
  noiseSuppression?: boolean
}

export interface AudioCaptureError {
  code: string
  message: string
  details?: string
}

export function useAudioCapture() {
  const isRecording = ref(false)
  const isConnecting = ref(false)
  const error = ref<AudioCaptureError | null>(null)
  const audioContext = ref<AudioContext | null>(null)
  const mediaStream = ref<MediaStream | null>(null)
  const processor = ref<ScriptProcessorNode | null>(null)
  const websocket = ref<WebSocket | null>(null)
  const connectionRetryCount = ref(0)
  const isSharedWebSocket = ref(false) // Flag para indicar se o WebSocket 칠 compartilhado
  
  const maxRetries = 3
  const retryDelay = 1000 // 1 segundo

  // Configura칞칚o padr칚o para captura de 치udio
  const defaultConfig: AudioCaptureConfig = {
    channelCount: 1,
    sampleRate: 16000,
    echoCancellation: true,
    noiseSuppression: true
  }

  /**
   * Verifica se o navegador suporta as APIs necess치rias
   */
  const checkBrowserSupport = (): boolean => {
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      setError('BROWSER_NOT_SUPPORTED', 'Navegador n칚o suporta captura de 치udio')
      return false
    }

    if (!window.AudioContext && !(window as any).webkitAudioContext) {
      setError('AUDIO_CONTEXT_NOT_SUPPORTED', 'Navegador n칚o suporta Web Audio API')
      return false
    }

    return true
  }

  /**
   * Solicita permiss칚o para acessar o microfone
   */
  const requestMicrophonePermission = async (config: AudioCaptureConfig = defaultConfig): Promise<MediaStream> => {
    try {
      const constraints: MediaStreamConstraints = {
        audio: {
          channelCount: config.channelCount,
          sampleRate: config.sampleRate,
          echoCancellation: config.echoCancellation,
          noiseSuppression: config.noiseSuppression
        }
      }

      const stream = await navigator.mediaDevices.getUserMedia(constraints)
      return stream
    } catch (err: any) {
      console.error('Erro ao solicitar permiss칚o do microfone:', err)
      
      switch (err.name) {
        case 'NotAllowedError':
          setError('PERMISSION_DENIED', 'Permiss칚o de acesso ao microfone negada pelo usu치rio')
          break
        case 'NotFoundError':
          setError('NO_MICROPHONE', 'Nenhum microfone encontrado no dispositivo')
          break
        case 'NotReadableError':
          setError('MICROPHONE_IN_USE', 'Microfone j치 est치 sendo usado por outro aplicativo')
          break
        case 'OverconstrainedError':
          setError('CONSTRAINTS_NOT_SATISFIED', 'Configura칞칫es de 치udio n칚o suportadas pelo dispositivo')
          break
        default:
          setError('MICROPHONE_ACCESS_ERROR', `Erro ao acessar microfone: ${err.message}`)
      }
      
      throw err
    }
  }

  /**
   * Estabelece conex칚o WebSocket com retry autom치tico
   */
  const connectWebSocket = async (wsUrl: string): Promise<WebSocket> => {
    return new Promise((resolve, reject) => {
      try {
        const ws = new WebSocket(wsUrl)
        
        const connectionTimeout = setTimeout(() => {
          ws.close()
          reject(new Error('Timeout na conex칚o WebSocket'))
        }, 10000) // 10 segundos de timeout

        ws.onopen = () => {
          clearTimeout(connectionTimeout)
          connectionRetryCount.value = 0
          console.log('WebSocket conectado com sucesso')
          resolve(ws)
        }

        ws.onerror = (err) => {
          clearTimeout(connectionTimeout)
          console.error('Erro no WebSocket:', err)
          reject(new Error('Falha na conex칚o WebSocket'))
        }

        ws.onclose = (event) => {
          clearTimeout(connectionTimeout)
          console.log('WebSocket fechado:', event.code, event.reason)
          
          // Se estava gravando e conex칚o foi perdida, tentar reconectar
          if (isRecording.value && connectionRetryCount.value < maxRetries) {
            setTimeout(() => {
              console.log(`Tentativa de reconex칚o ${connectionRetryCount.value + 1}/${maxRetries}`)
              connectionRetryCount.value++
              reconnectWebSocket(wsUrl)
            }, retryDelay * Math.pow(2, connectionRetryCount.value)) // Backoff exponencial
          }
        }
      } catch (err) {
        reject(err)
      }
    })
  }

  /**
   * Reconecta o WebSocket automaticamente
   */
  const reconnectWebSocket = async (wsUrl: string) => {
    try {
      websocket.value = await connectWebSocket(wsUrl)
    } catch (err) {
      console.error('Falha na reconex칚o:', err)
      if (connectionRetryCount.value >= maxRetries) {
        setError('WEBSOCKET_CONNECTION_FAILED', 'Falha na conex칚o com o servidor ap칩s m칰ltiplas tentativas')
        stopRecording()
      }
    }
  }

  /**
   * Inicia a grava칞칚o de 치udio
   */
  const startRecording = async (wsUrl: string | null, config: AudioCaptureConfig = defaultConfig, existingWebSocket?: WebSocket) => {
    try {
      // Evitar m칰ltiplas tentativas simult칙neas
      if (isConnecting.value || isRecording.value) {
        console.log('J치 conectando ou gravando, ignorando nova tentativa')
        return
      }

      clearError()
      isConnecting.value = true

      // Garantir que qualquer conex칚o anterior foi fechada completamente
      if (websocket.value && websocket.value.readyState !== WebSocket.CLOSED) {
        console.log('Aguardando fechamento de conex칚o anterior...')
        await cleanup()
        // Aguardar um pouco mais para garantir que tudo foi limpo
        await new Promise(resolve => setTimeout(resolve, 200))
      }

      // Verificar suporte do navegador
      if (!checkBrowserSupport()) {
        isConnecting.value = false
        return
      }

      console.log('Iniciando grava칞칚o com configura칞칚o:', config)

      // Usar WebSocket existente ou estabelecer nova conex칚o
      if (existingWebSocket && existingWebSocket.readyState === WebSocket.OPEN) {
        console.log('游댋 Usando WebSocket existente')
        websocket.value = existingWebSocket
        isSharedWebSocket.value = true
      } else if (wsUrl && wsUrl.trim() !== '') {
        console.log('游댋 Estabelecendo nova conex칚o WebSocket:', wsUrl)
        websocket.value = await connectWebSocket(wsUrl)
        isSharedWebSocket.value = false
      } else {
        throw new Error('Nem WebSocket existente nem URL fornecida')
      }

      // Solicitar acesso ao microfone
      mediaStream.value = await requestMicrophonePermission(config)

      // Configurar Web Audio API
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext
      audioContext.value = new AudioContextClass()

      // Criar n칩s de processamento de 치udio
      const source = audioContext.value.createMediaStreamSource(mediaStream.value)
      processor.value = audioContext.value.createScriptProcessor(4096, 1, 1)

      // Conectar n칩s de 치udio
      source.connect(processor.value)
      processor.value.connect(audioContext.value.destination)

      // Enviar dados de 치udio
      processor.value.onaudioprocess = (event: AudioProcessingEvent) => {
        if (!isRecording.value || !websocket.value || websocket.value.readyState !== WebSocket.OPEN) {
          return
        }

        const inputBuffer = event.inputBuffer.getChannelData(0)
        const int16Buffer = new Int16Array(inputBuffer.length)
        
        // Converter float32 para int16
        for (let i = 0; i < inputBuffer.length; i++) {
          int16Buffer[i] = Math.max(-32768, Math.min(32767, inputBuffer[i] * 32768))
        }

        try {
          // Enviar como ArrayBuffer
          websocket.value.send(int16Buffer.buffer)
          
          // Log peri칩dico (a cada ~2 segundos)
          if (Math.random() < 0.05) {
            console.log('游꿗 [AUDIO-SEND] Enviando chunk para backend:', {
              samples: int16Buffer.length,
              bytes: int16Buffer.buffer.byteLength,
              volume: Math.max(...Array.from(inputBuffer).map(Math.abs)).toFixed(4)
            })
          }
        } catch (error) {
          console.error('Erro ao enviar dados de 치udio:', error)
        }
      }

      isRecording.value = true
      isConnecting.value = false
      console.log('Grava칞칚o iniciada com sucesso')

    } catch (err: any) {
      console.error('Erro ao iniciar grava칞칚o:', err)
      isConnecting.value = false
      
      if (!error.value) { // Se o erro n칚o foi definido pelas fun칞칫es auxiliares
        setError('RECORDING_START_ERROR', `Erro ao iniciar grava칞칚o: ${err.message}`)
      }
      
      // Limpar recursos em caso de erro
      await cleanup()
      throw err
    }
  }

  /**
   * Para a grava칞칚o de 치udio
   */
  const stopRecording = async () => {
    console.log('Parando grava칞칚o')
    
    // Parar imediatamente o processamento de 치udio
    isRecording.value = false
    isConnecting.value = false
    
    // Cleanup imediato e ordenado
    await cleanup()
  }

  /**
   * Limpa todos os recursos
   */
  const cleanup = async () => {
    console.log('Iniciando cleanup de recursos de 치udio')
    
    // 1. Parar o processador de 치udio primeiro (para parar o envio)
    if (processor.value) {
      processor.value.onaudioprocess = null // Remove o callback imediatamente
      processor.value.disconnect()
      processor.value = null
      console.log('Processador de 치udio desconectado')
    }

    // 2. Parar as tracks de m칤dia
    if (mediaStream.value) {
      mediaStream.value.getTracks().forEach(track => {
        track.stop()
        console.log('Track de 치udio parado:', track.label)
      })
      mediaStream.value = null
    }

    // 3. Fechar o AudioContext
    if (audioContext.value && audioContext.value.state !== 'closed') {
      try {
        await audioContext.value.close()
        console.log('AudioContext fechado')
      } catch (err) {
        console.warn('Erro ao fechar AudioContext:', err)
      }
      audioContext.value = null
    }

    // 4. Fechar WebSocket de forma s칤ncrona (apenas se n칚o for compartilhado)
    if (websocket.value && websocket.value.readyState !== WebSocket.CLOSED && !isSharedWebSocket.value) {
      console.log('Fechando conex칚o WebSocket...')
      
      // Criar promise para aguardar o fechamento
      await new Promise<void>((resolve) => {
        if (!websocket.value || websocket.value.readyState === WebSocket.CLOSED) {
          resolve()
          return
        }

        const currentWs = websocket.value
        let resolved = false
        
        // Listener para quando o WebSocket fechar
        const onClose = () => {
          if (!resolved) {
            resolved = true
            console.log('WebSocket fechado completamente')
            currentWs.removeEventListener('close', onClose)
            clearTimeout(timeoutId)
            resolve()
          }
        }
        
        currentWs.addEventListener('close', onClose)
        
        // Fechar o WebSocket
        currentWs.close(1000, 'User stopped recording')
        
        // Timeout de seguran칞a (caso o close event n칚o dispare)
        const timeoutId = setTimeout(() => {
          if (!resolved) {
            resolved = true
            currentWs.removeEventListener('close', onClose)
            console.log('WebSocket fechado por timeout')
            resolve()
          }
        }, 1000)
      })
    } else if (websocket.value && isSharedWebSocket.value) {
      console.log('WebSocket compartilhado, apenas desconectando do processamento de 치udio')
    }
    
    websocket.value = null
    isSharedWebSocket.value = false

    connectionRetryCount.value = 0
    console.log('Cleanup conclu칤do')
  }

  /**
   * Converte Float32Array para Int16Array para formato PCM
   */
  const convertFloat32ToInt16 = (buffer: Float32Array): ArrayBuffer => {
    const l = buffer.length
    const buf = new Int16Array(l)

    for (let i = 0; i < l; i++) {
      // Clamping e scaling para Int16
      const sample = Math.min(1, Math.max(-1, buffer[i]))
      buf[i] = sample * 0x7FFF
    }

    return buf.buffer
  }

  /**
   * Define um erro
   */
  const setError = (code: string, message: string, details?: string) => {
    error.value = { code, message, details }
  }

  /**
   * Limpa o erro atual
   */
  const clearError = () => {
    error.value = null
  }

  /**
   * Obt칠m informa칞칫es sobre dispositivos de 치udio dispon칤veis
   */
  const getAudioDevices = async () => {
    try {
      if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
        throw new Error('enumerateDevices n칚o suportado')
      }

      const devices = await navigator.mediaDevices.enumerateDevices()
      return devices.filter(device => device.kind === 'audioinput')
    } catch (err: any) {
      console.error('Erro ao listar dispositivos de 치udio:', err)
      setError('DEVICE_ENUMERATION_ERROR', `Erro ao listar dispositivos: ${err.message}`)
      return []
    }
  }

  // Limpar recursos ao desmontar o componente
  onUnmounted(async () => {
    console.log('Componente desmontado, limpando recursos de 치udio')
    await stopRecording()
  })

  return {
    // Estados reativos
    isRecording,
    isConnecting,
    error,
    mediaStream,
    
    // M칠todos principais
    startRecording,
    stopRecording,
    clearError,
    getAudioDevices,
    
    // Utilit치rios
    checkBrowserSupport
  }
} 